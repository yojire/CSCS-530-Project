{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip = lambda y,x: x*y+(1-x)*(1-y)\n",
    "\n",
    "def cond_gen(x, alphas):\n",
    "    if type(alphas) == np.ndarray:\n",
    "        shape = alphas.shape\n",
    "    else:\n",
    "        shape = 1\n",
    "    Z = np.random.uniform(size=shape)**(1/alphas)\n",
    "    Y = flip(Z, x)\n",
    "    return(Y)\n",
    "\n",
    "cond_ltail = lambda y,alpha,x: flip(flip(y,x)**alpha, x)\n",
    "ltail = lambda y,alpha,p: p*cond_ltail(y,alpha,1)+(1-p)*cond_ltail(y,alpha,0)\n",
    "preftail = lambda y,alpha,p,pref: flip(ltail(y,alpha,p), 1-pref)\n",
    "\n",
    "cond_den = lambda y,alpha,x: alpha*flip(y,x)**(alpha-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class env:\n",
    "    \n",
    "    def __init__(self, n, alphas, pref, p=0.5):\n",
    "        alphas = -np.sort(-np.copy(alphas))\n",
    "        ids = np.arange(n)\n",
    "        np.random.shuffle(ids)\n",
    "        self.n = n\n",
    "        self.sys = pd.DataFrame({\n",
    "            'p':p, 'rank':np.arange(n),\n",
    "            'id':ids, 'alpha':alphas,\n",
    "            'pref':pref})\n",
    "        self.term = dict()\n",
    "    \n",
    "    def obsgen(self):\n",
    "        newx = np.random.binomial(1,self.sys['p'])\n",
    "        newy = cond_gen(newx, self.sys['alpha'])\n",
    "        self.sys['x'] = newx\n",
    "        self.sys['y'] = newy\n",
    "        return(self)\n",
    "    \n",
    "    def addcol(self, vec, colname):\n",
    "        self.sys[colname] = np.copy(vec)\n",
    "        return(self)\n",
    "    \n",
    "    def correct(self, subset):\n",
    "        self.sys.iloc[subset]['report'] = self.sys.iloc[subset]['y']\n",
    "        return(self)\n",
    "    \n",
    "    def newpos(self, subset, n=None):\n",
    "        if n is None:\n",
    "            n = self.n\n",
    "        subset = np.copy(subset)\n",
    "        m = subset.size\n",
    "        if m==0:\n",
    "            return(subset)\n",
    "        if subset.max()!=n-1:\n",
    "            return(subset+1)\n",
    "        temp = self.newpos(subset[:-1], n-1)\n",
    "        return(np.concatenate((temp, [n-1])))\n",
    "    \n",
    "    def rest(self, subset):\n",
    "        n = self.n\n",
    "        return(np.arange(n)[[i not in subset for i in range(n)]])\n",
    "    \n",
    "    def newrank(self, subset):\n",
    "        subset = np.copy(subset)\n",
    "        if subset.size==0:\n",
    "            return(np.arange(self.n))\n",
    "        nr = np.arange(self.n)\n",
    "        npos = self.newpos(subset)\n",
    "        nr[subset] = npos\n",
    "        nr[self.rest(subset)] = self.rest(npos)\n",
    "        return(nr)\n",
    "    \n",
    "    def penalize(self, subset):\n",
    "        nr = self.newrank(subset)\n",
    "        self.sys['rank'] = np.copy(self.sys['rank'][nr])\n",
    "        self.sys['alpha'] = np.copy(self.sys['alpha'][nr])\n",
    "        self.sys = self.sys.sort_values('rank')\n",
    "        self.addspec()\n",
    "        return(self)\n",
    "    \n",
    "    def addspec(self):\n",
    "        specloc = (self.sys['pref']*2-1)*(self.n-self.sys['rank'])\n",
    "        self.sys['spec'] = ss.rankdata(specloc, 'ordinal')\n",
    "        return(self)\n",
    "    \n",
    "    def investigate(self, subset):\n",
    "        dt = self.sys.iloc[subset]\n",
    "        dt2 = dt[dt['y']!=dt['report']]\n",
    "        self.guilty = dt2['rank']\n",
    "        self.guiltyid = np.copy(dt2.sort_values('id')['id'])\n",
    "        return(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nw(nx.Graph):\n",
    "    \n",
    "    a=1; k=0.5; pconn=0.5\n",
    "    \n",
    "    def tie_env(self, envir):\n",
    "        self.env = envir\n",
    "        envir.nw = self\n",
    "        return(self)\n",
    "    \n",
    "    def soc_prod(self,i,j):\n",
    "        return(self.env.sys.sort_values('id').iloc[[i,j]]['alpha'].prod())\n",
    "    \n",
    "    def diff(self,i,j):\n",
    "        locs = self.env.sys.sort_values('id').iloc[[i,j]]['spec']\n",
    "        return(np.abs(locs.iloc[0]-locs.iloc[1]))\n",
    "    \n",
    "    def shift(self,i,j):\n",
    "        if i>=j:\n",
    "            return(self)\n",
    "        socp = self.soc_prod(i,j)\n",
    "        d = self.diff(i,j)\n",
    "        pconn = nw.pconn\n",
    "        pbreak = pconn/((socp**nw.a)*np.exp(-nw.k*d))\n",
    "        if (i,j) in self.edges:\n",
    "            if np.random.binomial(1, pbreak):\n",
    "                self.remove_edge(i,j)\n",
    "        else:\n",
    "            if np.random.binomial(1, pconn):\n",
    "                self.add_edge(i,j)\n",
    "        return(self)\n",
    "    \n",
    "    def timestep(self):\n",
    "        for i in self.nodes:\n",
    "            for j in self.nodes:\n",
    "                self.shift(i,j)\n",
    "        return(self)\n",
    "    \n",
    "    def changepar(a=a, k=k, pconn=pconn):\n",
    "        nw.a, nw.k, nw.pconn = a, k, pconn\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prior(pd.DataFrame):\n",
    "    \n",
    "    stdgrid = np.arange(1,200,2)/200\n",
    "    stdval = 1\n",
    "    \n",
    "    def fill(self, p=stdgrid, f=stdval):\n",
    "        self['p']=p; self['f']=f\n",
    "        return(self)\n",
    "    \n",
    "    def integrate(self):\n",
    "        return(np.mean(self['f']))\n",
    "    \n",
    "    def pnormal(self):\n",
    "        self['f'] = self['f']/self.integrate()\n",
    "        return(self)\n",
    "    \n",
    "    def bayes(self,another):\n",
    "        output = prior().fill(self['p'], self['f']*another['f'])\n",
    "        return(output.pnormal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spvs:\n",
    "    \n",
    "    stdgrid = np.arange(1,200,2)/200\n",
    "    \n",
    "    def __init__(self, prior=prior().fill(), suspicion=0.05):\n",
    "        self.prior = prior\n",
    "        self.s = suspicion\n",
    "    \n",
    "    def tie_env(self, envir):\n",
    "        self.env = envir\n",
    "        envir.spvs = self\n",
    "        return(self)\n",
    "    \n",
    "    def bias(self):\n",
    "        self.b = np.mean(self.prior['f']*self.prior['p'])\n",
    "        return(self.b)\n",
    "    \n",
    "    def first_est(self, subset):\n",
    "        self.bias()\n",
    "        dt = self.env.sys.iloc[subset]\n",
    "        calratio = lambda row:cond_den(row['report'],row['alpha'],x=1)/cond_den(row['report'],row['alpha'],x=0)\n",
    "        ratios = dt.apply(calratio, axis=1)\n",
    "        ratio = ratios.prod()*self.b/(1-self.b)\n",
    "        return(ratio/(1+ratio))\n",
    "    \n",
    "    def suspects(self, subset, q):\n",
    "        dt = self.env.sys.iloc[subset].copy()\n",
    "        dt['bool'] = dt.apply(lambda row:preftail(row['report'],row['alpha'],q,row['pref'])<self.s, axis=1)\n",
    "        return(dt['rank'][dt['bool']])\n",
    "    \n",
    "    def decide(self):\n",
    "        calratio = lambda row:cond_den(row['report'],row['alpha'],x=1)/cond_den(row['report'],row['alpha'],x=0)\n",
    "        ratios = self.env.sys.apply(calratio, axis=1)\n",
    "        ratio = ratios.prod()*self.b/(1-self.b)\n",
    "        return(1 if ratio>1 else 0)\n",
    "    \n",
    "    def condist(prob, dt, colname='report'):\n",
    "        part1 = dt.apply(lambda row:cond_den(row[colname],row['alpha'],x=1), axis=1).prod()*prob\n",
    "        part2 = dt.apply(lambda row:cond_den(row[colname],row['alpha'],x=0), axis=1).prod()*(1-prob)\n",
    "        return(part1+part2)\n",
    "    \n",
    "    def update(self):\n",
    "        temp = prior().fill()\n",
    "        temp['f'] = temp.apply(lambda row:spvs.condist(row['p'],self.env.sys),axis=1)\n",
    "        self.prior = self.prior.bayes(temp)\n",
    "        return(self)\n",
    "    \n",
    "    def analysis(self):\n",
    "        n = self.env.n\n",
    "        test = np.sort(np.random.choice(range(n),int(n/2),False))\n",
    "        trust = np.arange(n)[[i not in test for i in range(n)]]\n",
    "        q = self.first_est(trust)\n",
    "        suspects = self.suspects(test, q)\n",
    "        self.env.investigate(suspects)\n",
    "        self.env.correct(suspects)\n",
    "        self.env.decision = self.decide()\n",
    "        self.update()\n",
    "        return(self)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class term:\n",
    "    \n",
    "    stdgrid = np.arange(1,200,2)/200\n",
    "    \n",
    "    def __init__(self, pid, prior=prior().fill(), sushat=0.05):\n",
    "        self.id = pid\n",
    "        self.prior = prior\n",
    "        self.sushat = sushat\n",
    "    \n",
    "    def tie_env(self, envir):\n",
    "        self.env = envir\n",
    "        self.nw = envir.nw\n",
    "        envir.term[self.id] = self\n",
    "        return(self)\n",
    "    \n",
    "    def bias(self):\n",
    "        self.b = np.mean(self.prior['f']*self.prior['p'])\n",
    "        return(self.b)\n",
    "    \n",
    "    def getinfo(self):\n",
    "        dt = self.env.sys\n",
    "        self.myinfo = dt[dt['id']==self.id]\n",
    "        neighbors = list(nx.neighbors(self.nw, self.id))\n",
    "        self.avinfo = dt.sort_values('id').iloc[neighbors]\n",
    "        self.info = pd.concat([self.myinfo, self.avinfo])\n",
    "        return(self)\n",
    "    \n",
    "    def condist(prob, dt, colname='y'):\n",
    "        part1 = dt.apply(lambda row:cond_den(row[colname],row['alpha'],x=1), axis=1).prod()*prob\n",
    "        part2 = dt.apply(lambda row:cond_den(row[colname],row['alpha'],x=0), axis=1).prod()*(1-prob)\n",
    "        return(part1+part2)\n",
    "    \n",
    "    def report(self):\n",
    "        q = self.bias()\n",
    "        self.getinfo()\n",
    "        pref = self.myinfo['pref'].iloc[0]\n",
    "        y = self.myinfo['y'].iloc[0]\n",
    "        calratio = lambda row:cond_den(row['y'],row['alpha'],x=1)/cond_den(row['y'],row['alpha'],x=0)\n",
    "        ratio = self.info.apply(calratio, axis=1).prod()*q/(1-q)\n",
    "        newq = ratio/(ratio+1)\n",
    "        caltail = lambda y: preftail(y, self.myinfo['alpha'], newq, pref)\n",
    "        tails = pd.Series(term.stdgrid).apply(caltail).iloc[:,0]\n",
    "        safe = term.stdgrid[pd.Series(tails)>self.sushat]\n",
    "        if safe.size==0:\n",
    "            return(y)\n",
    "        elif pref==1:\n",
    "            return(max(y, safe.max()))\n",
    "        else:\n",
    "            return(min(y, safe.min()))\n",
    "        \n",
    "    def updateprior(self):\n",
    "        temp = pd.Series(prior.stdgrid).apply(lambda p: term.condist(p, self.info))\n",
    "        self.prior = self.prior.bayes(pd.DataFrame({'f':temp}))\n",
    "        return(self)\n",
    "    \n",
    "    def gennewsus(self):\n",
    "        i,s = self.id, self.sushat\n",
    "        punid = self.env.guiltyid\n",
    "        punflag = (i in punid)\n",
    "        avid = self.avinfo['id']\n",
    "        avpun = avid[avid.apply(lambda i:(i in punid))]\n",
    "        jitter = lambda x:x*np.random.uniform(0.9, 1.1)\n",
    "        if avpun.size == 0:\n",
    "            self.newsus = jitter(1.1*s) if punflag else jitter(s)\n",
    "            return\n",
    "        estimates = [self.env.term[i].sushat for i in avpun]\n",
    "        maxest = max(estimates)\n",
    "        self.newsus = jitter(maxest) if punflag else jitter((s+min(s,maxest))/2)\n",
    "        return\n",
    "    \n",
    "    def updatesus(self):\n",
    "        self.sushat = self.newsus\n",
    "        return(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(n, npref, p=0.5):\n",
    "    envir = env(n, np.arange(2,3,1/n), np.random.choice([1]*npref+[0]*(n-npref), n, False), p=p)\n",
    "    envir.addcol(np.random.choice(np.arange(0.5,2,1/n),n,False), 'soc')\n",
    "    envir.addspec()\n",
    "    net = nw()\n",
    "    net.add_nodes_from(range(n))\n",
    "    net.tie_env(envir)\n",
    "    supervisor = spvs()\n",
    "    supervisor.tie_env(envir)\n",
    "    for i in range(n):\n",
    "        terminal = term(i)\n",
    "        terminal.tie_env(envir)\n",
    "    return(envir)\n",
    "\n",
    "def cycle(envir, log):\n",
    "    envir.nw.timestep()\n",
    "    envir.obsgen()\n",
    "    envir.repo = [envir.term[i].report() for i in envir.sys['id']]\n",
    "    envir.addcol(envir.repo, 'report')\n",
    "    envir.spvs.analysis()\n",
    "    envir.penalize(envir.guilty)\n",
    "    for i in range(n):\n",
    "        envir.term[i].updateprior()\n",
    "        envir.term[i].gennewsus()\n",
    "    for i in range(n):\n",
    "        envir.term[i].updatesus()\n",
    "    log.append(copy.deepcopy(envir))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try running the model in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = 9,5\n",
    "envir = initialize(n,m)\n",
    "nw.changepar(pconn=0.5/n, k=1/n, a=1)\n",
    "log = [copy.deepcopy(envir)]\n",
    "for i in range(10):\n",
    "    cycle(envir, log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you may then look into the log for further analysis. The following cell shows how more data can be generated altogether and saved for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "n=9\n",
    "wholelog = []\n",
    "\n",
    "for npref in np.arange(1,9):\n",
    "    envir = initialize(n,npref)\n",
    "    nw.changepar(pconn=0.5/n, k=1/n, a=1)\n",
    "    log = [copy.deepcopy(envir)]\n",
    "    for i in range(50):\n",
    "        cycle(envir, log)\n",
    "    wholelog.append(log)\n",
    "    \n",
    "filename = open(''.join(['one_instances.obj']),'wb')\n",
    "pickle.dump(wholelog, filename)\n",
    "filename.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code does not work well on Flux (though it is fine on my laptop, maybe there are some module issues on Flux), so I also wrote an R implementation for Flux comoputation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
